{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c2b1af-7386-486d-9204-65441aa5257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import f2py\n",
    "\n",
    "import time\n",
    "\n",
    "import eos\n",
    "import eos_t\n",
    "import universe\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeaa65d-90d1-4aab-ba0f-f735a75a72e9",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9fee19-72fe-4b26-832b-755aa3a3d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d1240b-03d3-4598-877c-30af842d2108",
   "metadata": {},
   "source": [
    "## New `spectrum.gmlt_spec_od_pwc_exact` implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a10c7-e740-4d79-9d0b-e070e450c56c",
   "metadata": {},
   "source": [
    "We try to keep a $N^2$ tensor, where each row corresponds to a Doppler profile. At the end, we sum over its vertical axis to get the cumulative profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a86db7-b136-424b-9f49-f7b6dd126957",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n",
      "x summed over vertical axis: tf.Tensor([24 28 32 36], shape=(4,), dtype=int64)\n",
      "\n",
      "x - diff:\n",
      " [[ 0  1  2  3]\n",
      " [ 3  4  5  6]\n",
      " [ 6  7  8  9]\n",
      " [ 9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate tf.reduce_sum\n",
    "x = np.reshape(np.arange(16), (4,4))\n",
    "print('x:\\n', x)\n",
    "print('x summed over vertical axis:', tf.reduce_sum(x, axis=0))\n",
    "\n",
    "print()\n",
    "\n",
    "# demonstrate broadcasting\n",
    "diff = np.reshape(np.arange(4), (4,1))\n",
    "print('x - diff:\\n', x - diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ae203-9a95-4ffa-acd1-853d69538ae4",
   "metadata": {},
   "source": [
    "[Rotate a tensor row-wise](https://stackoverflow.com/questions/58173427/how-to-rotate-a-tensor-row-wise-in-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24c3e81a-d65a-4c00-b1c6-4e90e6126196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather_nd doesn't mess with the gradient!\n",
    "\n",
    "# with tf.GradientTape() as tape:\n",
    "#     var = tf.Variable(2.0, dtype='float64')\n",
    "#     A = tf.Variable([[4, 0, 0],\n",
    "#               [1, 2, 3],\n",
    "#               [0, 0, 5]], dtype='float64')\n",
    "#     A = tf.multiply(A, var)\n",
    "#     B = tf.gather_nd(A, [[1,2]])\n",
    "\n",
    "# print('B:', B)\n",
    "# print('dB/dvar:', tape.gradient(B, var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7393f-62de-4392-a356-e954ba786b5d",
   "metadata": {},
   "source": [
    "[Roll rows of a matrix independently](https://stackoverflow.com/questions/20360675/roll-rows-of-a-matrix-independently) (NOTE: this solution messes with the gradient, so I don't implement it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a918dd62-8bf2-4c3d-b856-c663cca63413",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this solution doesn't work; indexing creates a gradient of None\n",
    "\n",
    "# with tf.GradientTape() as tape:\n",
    "#     tape.watch(var)\n",
    "#     tape.watch(A)\n",
    "#     tape.watch(B)\n",
    "    \n",
    "#     var = tf.Variable(2.0, dtype='float64')\n",
    "#     A = tf.Variable([[4, 0, 0],\n",
    "#               [1, 2, 3],\n",
    "#               [0, 0, 5]], dtype='float64')\n",
    "#     A = tf.multiply(A, var)\n",
    "#     B = tf.Variable(A[...])\n",
    "\n",
    "# print(tape.gradient(B, var))\n",
    "\n",
    "# roll rows independently (NOTE: this messes with the gradient)\n",
    "# A = np.array([[4, 0, 0],\n",
    "#               [1, 2, 3],\n",
    "#               [0, 0, 5]])\n",
    "# r = np.array([2, 0, -1])\n",
    "\n",
    "# rows, column_indices = np.ogrid[:A.shape[0], :A.shape[1]]\n",
    "\n",
    "# r = r % A.shape[1]\n",
    "# # shifting the \"origin\" to the right by r is the same as shifting it to the left by (n - r)\n",
    "# column_indices = column_indices - r[:, np.newaxis]\n",
    "# # if the first row of column_indices is [-1, 0, 1], then x = [a, b, c] is rolled to \n",
    "# # x_r = [x[-1], x[0], x[1]] = [c, a, b]\n",
    "\n",
    "# result = A[rows, column_indices]\n",
    "# print('rolled array:\\n', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0798aa93-8d0a-4bbe-992f-4102de97d50c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print('testing linspace:\\n', tf.linspace([0., 5.], [10., 40.], 5, axis=-1))\n",
    "\n",
    "# # demonstrate diag and inv\n",
    "# diag = tf.linalg.diag(np.arange(4) + 1)\n",
    "# diag = tf.cast(diag, dtype='float64')\n",
    "# tf.linalg.inv(diag)\n",
    "\n",
    "# # test tf.pad\n",
    "# paddings = tf.constant([[0, 0], [0, 6 - 4]])\n",
    "# tf.pad(x, paddings, \"CONSTANT\", constant_values=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db44a5-e945-4d0b-ae4f-ff58ffeb38d9",
   "metadata": {},
   "source": [
    "### pix_locations (a potential alternative to tf.roll and ipixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acfa79e-0840-4611-8d58-d1ad6d259c68",
   "metadata": {},
   "source": [
    "pix_locations would be a possible replacement for tf.roll and ipixes. It would have shape (N, N), with each row containing a profile's \"relevant\" index values located at those indices, e.g., one row could be [0, 0, 2, 3, 4, 0, ..., 0] or [4, 0, 2, 3]. In particular, it would allow different profiles to have different pixel window widths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ababbea-8820-4b8c-b4eb-df91589104e7",
   "metadata": {},
   "source": [
    "### implementation 1 of pix_locations (complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97754de2-50fa-41b4-95ac-9074750e70fb",
   "metadata": {},
   "source": [
    "This implementation uses a for-loop in two places. In the future, these might be replaced with (or without) vectorized_map in order to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "937f968a-35ef-42fd-ae96-a4afa64f938b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_x: tf.Tensor(\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [-100    0    0    0    0    0    0    0    0    0]\n",
      " [   0 -100    0    0    0    0    0    0    0    0]\n",
      " [   0    0 -100    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]], shape=(10, 10), dtype=int32)\n",
      "list of lists: [[0, 0], [1, 1, 1], [2, 2]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate scatter add\n",
    "x = tf.Variable(x)\n",
    "\n",
    "ind_list = [[1,0], [2, 1], [3, 2]]\n",
    "updates = [-100, -100, -100]\n",
    "new_x = tf.tensor_scatter_nd_add(x, ind_list, updates)\n",
    "print('new_x:', new_x)\n",
    "\n",
    "# get a list of lists\n",
    "iterations = tf.constant([2, 3, 2])\n",
    "row_nums_repeated = [[i]*((int) (iterations[i])) for i in range(3)]\n",
    "print('list of lists:', row_nums_repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "97107383-df4e-4d9a-9acd-17b7982c76a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_list: [[[0, 7], [0, 8], [0, 9], [0, 0], [0, 1], [0, 2]], [[1, 5], [1, 6], [1, 7]], [[2, 8], [2, 9], [2, 0], [2, 1]]]\n",
      "new_x: tf.Tensor(\n",
      "[[ 0  1  2  0  0  0  0 -3 -2 -1]\n",
      " [ 0  0  0  0  0  5  6  7  0  0]\n",
      " [10 11  0  0  0  0  0  0  8  9]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]], shape=(10, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# complete implementation (with 2 for-loops)\n",
    "\n",
    "n = 10\n",
    "x = tf.zeros([10, 10], dtype='int32')\n",
    "new_x = tf.identity(x)\n",
    "\n",
    "ipix_hi = tf.constant([2, 7, 11])\n",
    "ipix_lo = tf.constant([-3,5,8])\n",
    "profile_widths = ipix_hi - ipix_lo + 1\n",
    "\n",
    "# ragged tensor; the ith row is range(ipix_lo[i], ipix_hi[i] + 1)\n",
    "ipixes = tf.ragged.range(ipix_lo, ipix_hi + 1)\n",
    "\n",
    "# row_nums would go from 0 through N-1\n",
    "iterations = tf.identity(profile_widths)\n",
    "row_nums_repeated = [[i]*((int) (iterations[i])) for i in range(3)]\n",
    "row_nums_repeated = tf.ragged.constant(row_nums_repeated)\n",
    "#row_nums_repeated = tf.ragged.constant([[0, 0], [1, 1, 1], [2, 2]])\n",
    "\n",
    "# get the \"relevant\" index locations\n",
    "ind_list = tf.stack((row_nums_repeated, ipixes), axis=2)\n",
    "ind_list = ind_list % n # index wrapping\n",
    "print('ind_list:', ind_list.to_list())\n",
    "\n",
    "for i in range(3):\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, ind_list[i], ipixes[i])\n",
    "print('new_x:', new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081180c-85f0-4b6d-8859-37cdb3dad867",
   "metadata": {},
   "source": [
    "### implementation 2 of pix_locations (incomplete/flawed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f18e41-5aa5-4061-aec6-4c6037050590",
   "metadata": {},
   "source": [
    "This implementation is flawed. Currently, it doesn't handle indices that are out-of-bounds (e.g. 1024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4da407a2-661c-4ae1-ba76-933e414ddf32",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 10), dtype=bool, numpy=\n",
       "array([[False, False, False, False, False, False,  True,  True, False,\n",
       "        False],\n",
       "       [False, False, False, False, False,  True,  True,  True, False,\n",
       "        False],\n",
       "       [False, False, False,  True,  True, False, False, False, False,\n",
       "        False]])>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a mask to get the \"relevant\" indices\n",
    "n = 4\n",
    "\n",
    "ipix_hi = tf.constant([3, 3, 5])\n",
    "ipix_lo = tf.constant([0,1,2])\n",
    "\n",
    "pix_locations = tf.repeat([tf.range(n)], n, axis=0)\n",
    "\n",
    "mask = tf.logical_and(tf.range(n) >= ipix_lo[:, None],\n",
    "                      tf.range(n) <= ipix_hi[:, None])\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a342cd-bc97-4a30-ad17-150100b6a1e3",
   "metadata": {},
   "source": [
    "[Assigning to slices of a 2D array](https://stackoverflow.com/questions/48876162/assigning-to-slices-of-2d-numpy-array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c3f6fca9-0e6c-446d-9ebf-d38e47decca5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[False  True  True  True]\n",
      " [False False  True  True]\n",
      " [False False False  True]\n",
      " [False  True  True  True]], shape=(4, 4), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[0 2 3 4]\n",
      " [0 0 3 4]\n",
      " [0 0 0 4]\n",
      " [0 2 3 4]], shape=(4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "arr = tf.Variable([[1,2,3,4],\n",
    "                [1,2,3,4],\n",
    "                [1,2,3,4],\n",
    "                [1,2,3,4]])\n",
    "\n",
    "idxs = np.array([0,1,2,0])\n",
    "\n",
    "mask = tf.range(4) > idxs[:,None]\n",
    "#print(mask)\n",
    "arr = tf.multiply(tf.cast(mask, dtype='int32'), arr)\n",
    "#print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9db1f0-658c-4e64-bdd0-6b796d2a1e44",
   "metadata": {},
   "source": [
    "## Defining a function and its derivative\n",
    "[Custom gradients](https://www.tensorflow.org/guide/eager#custom_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ea1569-37ab-4f4c-90d7-beff1ef1b35f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "dz/dx: tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "dz/dy: tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.custom_gradient\n",
    "def bar(x, y): # f(x,y) = x * y\n",
    "    def grad(upstream): # pass in the \"upstream\" gradient\n",
    "        dz_dx = y\n",
    "        dz_dy = x\n",
    "        return upstream * dz_dx, upstream * dz_dy # pass grad \"downstream\"\n",
    "    z = x * y\n",
    "    return z, grad\n",
    "\n",
    "x = tf.constant(2.0, dtype=tf.float32)\n",
    "y = tf.constant(3.0, dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    "    tape.watch(y)\n",
    "    z = bar(x, y)\n",
    "    \n",
    "print('z:', z)\n",
    "print('dz/dx:', tape.gradient(z, x))\n",
    "print('dz/dy:', tape.gradient(z, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1938e9-b3f9-4004-9da1-03cf712f5cc9",
   "metadata": {},
   "source": [
    "## Vectorization with gmlt_spec_od_pwc_exact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a620af-8911-468c-9d48-9687bf9d9f12",
   "metadata": {},
   "source": [
    "### Outer loop (going through each cell in the LOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b157799-e4d1-4995-a182-341a1be0dc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array = tf.constant((3, 6, 0, 7), dtype=tf.float64)\n",
    "\n",
    "# assert all(i > 0 for i in n_array), \"n_array should only have positive values\"\n",
    "\n",
    "# only look at cells where n > 0\n",
    "inds = np.arange(tf.size(n_array).numpy())\n",
    "inds = inds[(n_array > 0).numpy()]\n",
    "inds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca15a1-a204-4de5-b508-42c9a2f3cc24",
   "metadata": {},
   "source": [
    "### Inner loop (adding the Doppler profile to the tau skewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8132f066-ff6c-49b6-a23a-1dc08ecc3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10 # LOS length; same as num_pixels and num_elements\n",
    "\n",
    "def ind_wrap(i):\n",
    "    '''\n",
    "    Performs util.gmlt_index_wrap on an index, where r (in this case, l) is \n",
    "    pre-specified outside the scope of this method.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    i: index (an int tensor)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return util.gmlt_index_wrap(i, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f658da-33a8-4dc9-99f1-13b11d497540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[6]\n",
      " [7]\n",
      " [8]\n",
      " [9]\n",
      " [0]\n",
      " [1]\n",
      " [2]], shape=(7, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[1.04099972e-21 4.45605255e-22 3.34879004e-23 4.06208906e-25\n",
      " 7.42901733e-28 1.96608723e-31 7.32747173e-36], shape=(7,), dtype=float64)\n",
      "tf.Tensor(\n",
      "[7.42901733e-28 1.96608723e-31 7.32747173e-36 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.04099972e-21 4.45605255e-22\n",
      " 3.34879004e-23 4.06208906e-25], shape=(10,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "ipixes = tf.constant(range(6,13), dtype=tf.int32)\n",
    "jw = tf.map_fn(ind_wrap, ipixes)\n",
    "jw = tf.reshape(jw, [tf.size(jw).numpy(), 1]) # necessary for tensor_scatter_nd_add\n",
    "\n",
    "v_domain = tf.constant(1.0e5, dtype=tf.float64) # fake data\n",
    "pixel_dv = v_domain / l\n",
    "\n",
    "ipixes = tf.cast(ipixes, dtype=tf.float64)\n",
    "v_pixel = tf.math.multiply(pixel_dv, tf.math.add(ipixes,0.5))\n",
    "#jw = tf.map_fn(test_ind_wrap, ipixes)\n",
    "\n",
    "# more fake data\n",
    "vlc_l = pixel_dv * 6\n",
    "vlc_h = pixel_dv * 7\n",
    "\n",
    "v_doppler = 1.0e4\n",
    "dxl = (v_pixel - vlc_l) / v_doppler\n",
    "dxh = (v_pixel - vlc_h) / v_doppler\n",
    "\n",
    "n_array = tf.cast(tf.ones([l]) * 1e-21, dtype=tf.float64)\n",
    "tau_array = tf.cast(tf.zeros([l]), dtype=tf.float64)\n",
    "\n",
    "# calculate tau\n",
    "tau_i = tf.math.multiply(n_array[6], (tf.math.erf(dxl) - tf.math.erf(dxh)))\n",
    "tau_array = tf.tensor_scatter_nd_add(tau_array, jw, tau_i)\n",
    "\n",
    "print(jw)\n",
    "print(tau_i)\n",
    "print(tau_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6fd05-ceb2-4fa7-8f3d-2e67325acf8c",
   "metadata": {},
   "source": [
    "## Vectorization with gmlt_spec_od_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fcc3c-fedf-489d-ad85-47933e6b3ed6",
   "metadata": {},
   "source": [
    "### outline\n",
    "- arr has shape (x,y,z)\n",
    "- reshape arr to (x*y, z)\n",
    "- vectorized_map(fn, arr) returns arr2, shape (x*y, z)\n",
    "    - here, fn is gmlt_spec_od_pwc_exact\n",
    "- reshape arr2 to (x,y,z)\n",
    "- create od_pwc_exact2: only arg is a tuple of the 3 grids, while snapshot-specific args (e.g. redshift) are specified outside the function\n",
    "    - define this within gmlt_spec_od_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60580bc6-862c-4551-bcaa-ecd1c013640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  2  4  6]\n",
      " [ 8 10 12 14]\n",
      " [16 18 20 22]\n",
      " [24 26 28 30]\n",
      " [32 34 36 38]\n",
      " [40 42 44 46]], shape=(6, 4), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[ 0  2  4  6]\n",
      "  [ 8 10 12 14]\n",
      "  [16 18 20 22]]\n",
      "\n",
      " [[24 26 28 30]\n",
      "  [32 34 36 38]\n",
      "  [40 42 44 46]]], shape=(2, 3, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def fn(a, factor):\n",
    "    return a*factor\n",
    "\n",
    "fact = 2\n",
    "def fn2(a):\n",
    "    return fn(a, fact)\n",
    "\n",
    "# testing tf.reshape\n",
    "\n",
    "arr = tf.constant(np.arange(24).reshape(2,3,4))\n",
    "#print(arr)\n",
    "\n",
    "# we want to reshape arr to [[0,1,2,3], ..., [20,21,22,23]]\n",
    "arr = tf.reshape(arr, (6, 4))\n",
    "\n",
    "# arr2 = tf.vectorized_map(fn2, arr)\n",
    "arr2 = tf.map_fn(fn2, arr, fn_output_signature=tf.int64)\n",
    "print(arr2)\n",
    "print(tf.reshape(arr2, (2,3,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dce947-5029-48c7-aa32-0c2a421386f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function()\n",
    "def outer_product(a):\n",
    "    return tf.tensordot(a, a, 0)\n",
    "\n",
    "batch_size = 10\n",
    "a = tf.ones((batch_size, 4, 4))\n",
    "c = tf.vectorized_map(outer_product, a)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a768f7-6928-4f11-a2c2-6cde08de7b63",
   "metadata": {},
   "source": [
    "## Vectorization with nyx_eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d93583e-fe9e-4377-ad3c-f5442682b896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.087522466956245e+23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_obj = eos.EOS_at_z(2.99)\n",
    "\n",
    "# nyx_eos can accept tensors of different dtypes without errors\n",
    "t1 = tf.Variable([2], dtype=tf.int32)\n",
    "t2 = tf.constant([2], dtype=tf.float64)\n",
    "eos_obj.nyx_eos_vec((t1, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "024da478-87a0-4ad8-bf62-8ea3cac21cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method EOS_at_z.nyx_eos_vec of <eos.EOS_at_z object at 0x2aab1f693c50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method EOS_at_z.nyx_eos_vec of <eos.EOS_at_z object at 0x2aab1f693c50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float64, numpy=\n",
       "array([0.00000000e+00, 4.54376123e+23, 9.08752247e+23, 1.36312837e+24,\n",
       "       1.81750449e+24, 2.27188062e+24, 2.72625674e+24, 3.18063286e+24,\n",
       "       3.63500899e+24, 4.08938511e+24, 4.54376123e+24, 4.99813736e+24,\n",
       "       5.45251348e+24, 5.90688960e+24, 6.36126573e+24, 6.81564185e+24,\n",
       "       7.27001797e+24, 7.72439410e+24, 8.17877022e+24, 8.63314634e+24,\n",
       "       9.08752247e+24, 9.54189859e+24, 9.99627471e+24, 1.04506508e+25,\n",
       "       1.09050270e+25, 1.13594031e+25, 1.18137792e+25, 1.22681553e+25,\n",
       "       1.27225315e+25, 1.31769076e+25, 1.36312837e+25, 1.40856598e+25,\n",
       "       1.45400359e+25, 1.49944121e+25, 1.54487882e+25, 1.59031643e+25,\n",
       "       1.63575404e+25, 1.68119166e+25, 1.72662927e+25, 1.77206688e+25,\n",
       "       1.81750449e+25, 1.86294211e+25, 1.90837972e+25, 1.95381733e+25,\n",
       "       1.99925494e+25, 2.04469256e+25, 2.09013017e+25, 2.13556778e+25,\n",
       "       2.18100539e+25, 2.22644300e+25, 2.27188062e+25, 2.31731823e+25,\n",
       "       2.36275584e+25, 2.40819345e+25, 2.45363107e+25, 2.49906868e+25,\n",
       "       2.54450629e+25, 2.58994390e+25, 2.63538152e+25, 2.68081913e+25,\n",
       "       2.72625674e+25, 2.77169435e+25, 2.81713196e+25, 2.86256958e+25,\n",
       "       2.90800719e+25, 2.95344480e+25, 2.99888241e+25, 3.04432003e+25,\n",
       "       3.08975764e+25, 3.13519525e+25, 3.18063286e+25, 3.22607048e+25,\n",
       "       3.27150809e+25, 3.31694570e+25, 3.36238331e+25, 3.40782093e+25,\n",
       "       3.45325854e+25, 3.49869615e+25, 3.54413376e+25, 3.58957137e+25,\n",
       "       3.63500899e+25, 3.68044660e+25, 3.72588421e+25, 3.77132182e+25,\n",
       "       3.81675944e+25, 3.86219705e+25, 3.90763466e+25, 3.95307227e+25,\n",
       "       3.99850989e+25, 4.04394750e+25, 4.08938511e+25, 4.13482272e+25,\n",
       "       4.18026033e+25, 4.22569795e+25, 4.27113556e+25, 4.31657317e+25,\n",
       "       4.36201078e+25, 4.40744840e+25, 4.45288601e+25, 4.49832362e+25])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(np.arange(100).reshape(10,10), dtype=tf.double)\n",
    "y = tf.Variable(np.arange(100).reshape(10,10), dtype=tf.double)\n",
    "\n",
    "size = tf.size(x).numpy()\n",
    "#elems=(x,y)\n",
    "elems = (tf.reshape(x, [size]), tf.reshape(y, [size]))\n",
    "\n",
    "# vectorized_map throws a \"[Tensor] can't be converted to double\" error\n",
    "#tf.vectorized_map(eos_obj.nyx_eos_vec, elems)\n",
    "tf.map_fn(eos_obj.nyx_eos_vec, elems, fn_output_signature=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6bfe77-f160-476c-a201-5dc85de477e4",
   "metadata": {},
   "source": [
    "## Vectorization example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b82088-ebe3-48a4-9574-894872227103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function with specified parameter types can accept tf.Tensors\n",
    "def fn2(a: float, b: float):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20773cc0-9e2b-4c91-8d45-4d346bc5a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elems is a set of tensors, c is a number\n",
    "def fn(elems, c=3):\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "    print('eager:', tf.executing_eagerly()) # still False\n",
    "\n",
    "    # convert_to_tensor doesn't fix it\n",
    "    a = tf.convert_to_tensor(elems[0], dtype=tf.float32, name='test')\n",
    "    b = elems[1]\n",
    "    \n",
    "    print('a:', a)\n",
    "    print('type(a):', type(a))\n",
    "    print('eager:', tf.executing_eagerly())\n",
    "    \n",
    "    # nyx_eos does NOT accept tf.Tensors\n",
    "    # (when using vectorized_map, a is a tf.Tensor)\n",
    "    print(eos_obj.nyx_eos_vec((3,a)))\n",
    "    \n",
    "    #print(fn2(a,b))\n",
    "    \n",
    "    return a + b + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2ce5b-560f-4f7f-808b-39fbfc946b38",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "Getting the value of a tf.Tensor: https://stackoverflow.com/questions/33633370/how-to-print-the-value-of-a-tensor-object-in-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "780eda6c-a2ee-41dc-ae14-015ae7e0f881",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: True\n",
      "eager: False\n",
      "a: Tensor(\"loop_body/GatherV2:0\", shape=(10,), dtype=float32)\n",
      "type(a): <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "eager: False\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    /global/homes/j/jupiter/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:188 f  *\n        iters,\n    /global/homes/j/jupiter/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:248 _pfor_impl  **\n        loop_fn_outputs = loop_fn(loop_var)\n    /global/homes/j/jupiter/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:472 loop_fn\n        return fn(gathered_elems)\n    <ipython-input-15-5c3bb74a1f94>:16 fn\n        print(eos_obj.nyx_eos_vec((3,a)))\n    /global/u2/j/jupiter/lya-tf/lya_fields/eos.py:49 nyx_eos_vec\n        return eos_t.eos.nyx_eos(self.z, rhob, temp)\n\n    SystemError: eos_t.eos.nyx_eos() 3rd argument (t) can't be converted to double\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-35d86aa1b744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eager:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorized_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#time_stats(time.time() - start, 10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\u001b[0m in \u001b[0;36mvectorized_map\u001b[0;34m(fn, elems, fallback_to_while_loop)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m   return pfor(loop_fn, batch_size,\n\u001b[0;32m--> 490\u001b[0;31m               fallback_to_while_loop=fallback_to_while_loop)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\u001b[0m in \u001b[0;36mpfor\u001b[0;34m(loop_fn, iters, fallback_to_while_loop, parallel_iterations)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_functions_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfunctions_run_eagerly\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_functions_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions_run_eagerly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    /global/homes/j/jupiter/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:188 f  *\n        iters,\n    /global/homes/j/jupiter/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:248 _pfor_impl  **\n        loop_fn_outputs = loop_fn(loop_var)\n    /global/homes/j/jupiter/.conda/envs/lya-tf/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:472 loop_fn\n        return fn(gathered_elems)\n    <ipython-input-15-5c3bb74a1f94>:16 fn\n        print(eos_obj.nyx_eos_vec((3,a)))\n    /global/u2/j/jupiter/lya-tf/lya_fields/eos.py:49 nyx_eos_vec\n        return eos_t.eos.nyx_eos(self.z, rhob, temp)\n\n    SystemError: eos_t.eos.nyx_eos() 3rd argument (t) can't be converted to double\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(np.arange(100).reshape(10,10), dtype=tf.float32)\n",
    "y = tf.constant(np.arange(100).reshape(10,10), dtype=tf.float32)\n",
    "elems = (x,y)\n",
    "\n",
    "start = time.time()\n",
    "print('eager:', tf.executing_eagerly())\n",
    "out = tf.vectorized_map(fn, elems=elems)\n",
    "\n",
    "#time_stats(time.time() - start, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ed137-1e24-45b0-a487-73fba8652eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b09a18-a159-40d2-83dd-56cb086e4060",
   "metadata": {},
   "source": [
    "## Assigning an element to an existing tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "484ebdfa-9778-4caa-ab8c-0d1b6dc7acf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = tf.zeros([3,3,3])\n",
    "#tf.tensor_scatter_nd_add?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76925059-1a5c-48f7-902f-8a1914ed85de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 3), dtype=float32, numpy=\n",
       "array([[[0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [2., 2., 2.]],\n",
       "\n",
       "       [[3., 3., 3.],\n",
       "        [4., 4., 4.],\n",
       "        [5., 5., 5.]],\n",
       "\n",
       "       [[6., 6., 6.],\n",
       "        [7., 7., 7.],\n",
       "        [8., 8., 8.]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewer = tf.zeros([3])\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        x = tf.tensor_scatter_nd_add(x, [[i,j]], [skewer])\n",
    "        skewer = skewer + 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b47f1073-f057-4157-aa1a-40aaeb1dbe5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 3., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.zeros([3])\n",
    "tf.tensor_scatter_nd_add(x, [[1]], [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fdc33e-25ff-42bd-b68a-89e950e9a82b",
   "metadata": {},
   "source": [
    "## Testing speed of tensor access\n",
    "\n",
    "It takes too long to access a tensor's entries one-by-one; I need to avoid this when I'm passing fields into the EOS or optical depth routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55b80325-ecaa-45ed-817e-92b048866772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stats(duration, n):\n",
    "    rate = duration / n**2\n",
    "    print(\"Duration:\", np.round(duration, 4))\n",
    "    print(\"Hours needed to access 1024^3 entries:\", \n",
    "      np.round(rate * 1024**3 / 3600, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8bbf403-fac1-444e-bf6f-74e425fd200f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0.0072\n",
      "Hours needed to access 1024^3 entries: 86.2777\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "field = tf.zeros((n,n))\n",
    "total = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        total += field[i,j]\n",
    "\n",
    "duration = time.time() - start\n",
    "time_stats(duration, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd231c7-d919-4180-bdc2-f150fab9b4fd",
   "metadata": {},
   "source": [
    "### Nested loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbdcbdcf-b6f4-4857-ac2c-3ffdb9dcebd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int32, numpy=10>, <tf.Tensor: shape=(), dtype=float32, numpy=15.0>)\n",
      "Duration: 0.0294\n",
      "Hours needed to access 1024^3 entries: 87.5833\n"
     ]
    }
   ],
   "source": [
    "count = 15\n",
    "n = 10\n",
    "field = tf.zeros((n,n))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# outer loop\n",
    "i = tf.constant(0)\n",
    "condition1 = lambda i, count: tf.less(i, n)\n",
    "\n",
    "def body1(i, r): # index i and result r\n",
    "    # inner loop\n",
    "    j = tf.constant(0)\n",
    "    condition2 = lambda i,j,r: tf.less(j, n)\n",
    "    \n",
    "    def body2(i, j, r):\n",
    "        r += field[i,j]\n",
    "        return i, tf.add(j, 1), r\n",
    "    \n",
    "    i, j, r = tf.while_loop(condition2, body2, loop_vars=[i,j, r])\n",
    "    \n",
    "    # increment r\n",
    "    return tf.add(i, 1), r\n",
    "\n",
    "# do the loop:\n",
    "r = tf.while_loop(condition1, body1, [i, count])\n",
    "print(r)\n",
    "\n",
    "duration = time.time() - start\n",
    "time_stats(duration, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48ec23-8e6a-44ef-8e27-7a0ee43e2310",
   "metadata": {},
   "source": [
    "## Testing tf gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "050ed521-66d7-4907-a1bb-3bb9cccb4f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=36.0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.pow(z, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62c87d49-71a5-4543-b903-2739872cfdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tf.Tensor(0.25, shape=(), dtype=float32)\n",
      "grad: tf.Tensor(-0.0625, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "z = tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(z) # without this line, grad is None\n",
    "    a = tf.divide(1, z+1)\n",
    "    print('a:', a)\n",
    "    \n",
    "grad = tape.gradient(a, z)\n",
    "print('grad:', grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7edee72-2aa3-4c22-8d66-102dce21eead",
   "metadata": {},
   "source": [
    "# Wrapping Fortran functions to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b64ff-34b2-430e-a5c8-eb0f442ebc1b",
   "metadata": {},
   "source": [
    "[Three ways to wrap](https://numpy.org/doc/stable/f2py/f2py.getting-started.html)\n",
    "\n",
    "- Quick way (this requires Python 3.7 and NumPy 1.18): `python3 -m numpy.f2py -c eos-t.f90 -m eos_t`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7ab1a10-a491-4d29-a7ab-36e03bbe39f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e61e8510-c70c-47fc-979e-800ceb2777fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.26271073e-10 1.25558019e-10 1.24848791e-10 ... 6.57445059e-19\n",
      " 6.47458444e-19 6.37622769e-19]\n"
     ]
    }
   ],
   "source": [
    "eos_t.atomic_rates.tabulate_rates()\n",
    "print(eos_t.atomic_rates.alphahp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194f80d-bf3f-4e01-81fb-6a93faeb0a8e",
   "metadata": {},
   "source": [
    "# Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4603af4-2521-4c63-9245-a0b0c3a49b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../../../../../cscratch1/sd/jupiter/sim2_z3_FGPA_cgs.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b275758-854f-4696-b5ed-c126efdde728",
   "metadata": {},
   "source": [
    "## Testing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad74e4b1-33f9-4d43-bdd0-9822657c03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snapshot\n",
    "import pickle\n",
    "\n",
    "snap = snapshot.Snapshot(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "058ee92d-3c5c-47dd-9072-e436712473b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### test snapshot methods\n",
    "start = time.time()\n",
    "\n",
    "## while on the Cori GPU node, loading a full 1024^3 field throws an error \n",
    "# (possibly due to GPU memory being full)\n",
    "#temp = snap.read_field('/native_fields/temperature')\n",
    "#rhob = snap.read_field('/native_fields/baryon_density')\n",
    "# print(temp.shape)\n",
    "# print(temp.size)\n",
    "# print('Time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8146bd6c-8a28-41de-b1f4-8c7ef60dcd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1024, 1024]\n",
      "tf.Tensor([2.05993652e-02 2.10937500e+01 2.10937500e+01], shape=(3,), dtype=float64)\n",
      "Time: 10.777246952056885\n"
     ]
    }
   ],
   "source": [
    "# test read_field2 (reading in n^3 grids)\n",
    "start = time.time()\n",
    "shape = [1,1024,1024]\n",
    "\n",
    "# loading in 2 1x1024^2 fields went okay, but 10*1024^2 threw an error\n",
    "rhob2 = snap.read_subfield('/native_fields/baryon_density', shape)\n",
    "temp2 = snap.read_subfield('/native_fields/temperature', shape)\n",
    "print(temp2.shape)\n",
    "print(temp2.size)\n",
    "print('Time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08babae-10a2-4bee-98b8-59c475cbccc2",
   "metadata": {},
   "source": [
    "### universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acfee78b-119b-4aa8-a234-116d1266516b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=2.2856888888888885e+25>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = snap.universe\n",
    "chi = 10\n",
    "z = 1\n",
    "u.chi_to_proper_cgs(chi, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f75f47-fb47-4345-86d9-1713e3f3faea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float64, numpy=0.675>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c2b33-124a-4da1-ac17-ce3773aacfe3",
   "metadata": {},
   "source": [
    "### Saving the universe and eos_obj objects (see [this link](https://stackoverflow.com/questions/4529815/saving-an-object-data-persistence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "938417bc-858b-4478-ad58-450588f2a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "884d1481-0e4e-40ea-acf3-ed7a0043c02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float64, numpy=0.675>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_object(u, 'universe.pkl')\n",
    "\n",
    "with open('universe.pkl', 'rb') as inp:\n",
    "    univ2 = pickle.load(inp)\n",
    "\n",
    "univ2.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910722b0-9732-498f-9074-6e9fc0d854e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3b0f4e-162e-482b-8a7e-56b28ffde74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_b = u.omega_b\n",
    "h = u.h\n",
    "\n",
    "rho_crit_100_cgs = 1.8788200386793017e-29\n",
    "mean_rhob_cgs = omega_b * h*h * rho_crit_100_cgs\n",
    "z = 2.9999991588912964\n",
    "a = 1 / (z + 1)\n",
    "a3_inv = 1.0 / (a * a * a)\n",
    "rhob_cgs_conversion = mean_rhob_cgs * a3_inv\n",
    "\n",
    "eos_obj = eos.EOS_at_z(z, rhob_cgs_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1b9ae7d-58e2-45c1-a286-a1b16301746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(eos_obj, 'eos_obj.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f092ad-5dcf-4f55-af08-48eba08c8a40",
   "metadata": {
    "tags": []
   },
   "source": [
    "### eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "336c4016-5c2e-4278-9de0-a08613e07202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.485004133494724e-09"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eos\n",
    "\n",
    "eos_obj = eos.EOS_at_z(snap.z, rhob_cgs_conversion)\n",
    "# returns nhi\n",
    "#eos_obj.nyx_eos(rhob2.field[0,0,0] * 1e-29, temp2.field[0,0,0])\n",
    "eos_obj.nyx_eos(1e-29, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc1680a-afdf-4045-986d-17aeaf87633d",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1efd919-0f98-426a-8d85-709ff4774d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test the \"in\" keyword\n",
    "snap = h5py.File(filename,'r')\n",
    "\n",
    "name = 'aux_fields'\n",
    "\n",
    "snap.keys()\n",
    "\n",
    "if name in snap:\n",
    "    print('ok')\n",
    "    \n",
    "snap.close()\n",
    "\n",
    "shape = snap['domain'].attrs['shape']\n",
    "size = snap['domain'].attrs['size']\n",
    "\n",
    "z = snap['universe'].attrs['redshift']\n",
    "omega_b = snap['universe'].attrs['omega_b']\n",
    "omega_m = snap['universe'].attrs['omega_m']\n",
    "omega_l = snap['universe'].attrs['omega_l']\n",
    "h = snap['universe'].attrs['hubble']\n",
    "\n",
    "scale_factor = 1.0 / (1.0 + z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e41af2-0130-43d2-9ee7-0dc0e850d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shape)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e959a-eaf6-4272-8b2e-ddb388a1bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603dc22e-46b1-4028-b819-c98f8567d6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lya-TF",
   "language": "python",
   "name": "lya-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
